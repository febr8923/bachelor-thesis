
WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.

finished warm-up
model_loc: cpu, exec_loc: cpu
Allocated memory: 0.00MB
Reserved memory: 0.00MB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
Allocated memory: 0.00MB
Reserved memory: 0.00MB
--------
model_loc: cpu, exec_loc: gpu
Allocated memory: 0.00MB
Reserved memory: 0.00MB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.89it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.14it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]
Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
Allocated memory: 26465.18MB
Reserved memory: 26538.00MB
--------
model_loc: gpu, exec_loc: cpu
Allocated memory: 32.00MB
Reserved memory: 32.00MB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.95it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]
Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
Allocated memory: 32.00MB
Reserved memory: 26570.00MB
--------
model_loc: gpu, exec_loc: gpu
Allocated memory: 32.00MB
Reserved memory: 32.00MB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]
Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.
Allocated memory: 26497.18MB
Reserved memory: 27698.00MB
--------
finished warm-up
Traceback (most recent call last):
  File "/users/fbrunne/projects/benchmarks/run.py", line 297, in <module>
    raise ValueError("Invalid model type")
ValueError: Invalid model type
srun: error: nid007663: task 0: Exited with exit code 1
srun: Terminating StepId=920804.1
