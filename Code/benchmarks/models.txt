vgg19,dl
resnet50,dl
alexnet,dl
bert-large-uncased,dl

EleutherAI/gpt-j-6b,llm
meta-llama/Llama-3.1-8B,llm
meta-llama/Llama-3.1-405B

prompts:
intel dataset (pytorch version)#
multiple different sizes -> mulitipe lines for 4 different sizes, four lines in one graphic

- add batch size

model in 3d:
memory requirement
performance
cost
 - sm utilization
 - how much memory
 - load time

plot on this 3d space

2 cases:
- different work loads and different comain
- 2-3 analyze input  -> how does changing them 

assumption
 - sm b*memory
 - how much memory is it using 

1) for all application meansure
    measure time for data movement
    how much memory using (nvidia-smi; query interface); measure data points at every time. 
    compute utilization (cpu: mpstat 1 (columns of cpu is used); gpu: )
    performance
    nr. of sms

2) 

3) vary batch-size


What kind of plots?
- Vary nr. of SMs and load & execution time
    - 2 different scenarios gpu, cpu
- Vary batch size (1,2,4,8,16,32,64,128,256,512) w. fixed input length (e.g. 128)
    - 2 different scenarios gpu, cpu
- Vary input length (128, 256, 512, 1024, 2048) w. fixed batch size (e.g. 4)
    - 2 different scenarios gpu, cpu
- Measure memory and utilization under different scenarios